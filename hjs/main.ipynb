{"cells":[{"metadata":{"_uuid":"aecd036c-95e5-487e-8912-f96879dbd472","_cell_guid":"16d3b88e-07ee-4bd6-b37d-b39850b4a032","trusted":true},"cell_type":"code","source":"import os\nimport time\nimport random\nimport datetime\n\nimport numpy as np \nimport pandas as pd\nimport xgboost as xgb\nimport lightgbm as lgb\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn import preprocessing\nfrom sklearn import decomposition\nfrom sklearn import model_selection","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load data\ndatapath = '/kaggle/input'\ntrainid_df = pd.read_csv(os.path.join(datapath, 'train_identity.csv'))\ntraintx_df = pd.read_csv(os.path.join(datapath, 'train_transaction.csv'))\ntestid_df = pd.read_csv(os.path.join(datapath, 'test_identity.csv'))\ntesttx_df = pd.read_csv(os.path.join(datapath, 'test_transaction.csv'))\nsubmit_df = pd.read_csv(os.path.join(datapath, 'sample_submission.csv'))\n\n# TODO: train_identity = pd.read_csv(f'{folder_path}train_identity.csv', dtype={'TransactionAmt': str})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# merge dfs\ntrain_df = traintx_df.merge(trainid_df, how='left', left_index=True, right_index=True)\ntest_df = testtx_df.merge(testid_df, how='left', left_index=True, right_index=True)\n\nx = train_df['isFraud'].value_counts().values\nsns.barplot([0,1],x)\nplt.title('Target variable count')\n\n# unload raw csvs from the memory\ndel trainid_df\ndel traintx_df\ndel testid_df\ndel testtx_df\n\nprint(train_df.info())\nprint(test_df.info())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2f4549c5-afe9-492c-81fd-98d8c6caf539","_cell_guid":"c1b0de88-b929-48ec-8965-deaa7efe6432","trusted":true},"cell_type":"code","source":"# remove columns with a high proportion of null values\nnb_rows = train_df.shape[0]\ncols_to_remove = []\nfor col in train_df.columns:\n    if train_df[col].isna().sum()/nb_rows >= .9:\n        cols_to_remove.append(col)\n\ntrain_df.drop(cols_to_remove, axis=1, inplace=True)\ntest_df.drop(cols_to_remove, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9bcc5db4-d018-4ce3-8226-067a211157e1","_cell_guid":"422cb5ea-10e2-41da-a447-14878025b080","trusted":true},"cell_type":"code","source":"cat_cols = [\n    'id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_18', 'id_19',\n    'id_20', 'id_21', 'id_22', 'id_23', 'id_24', 'id_25', 'id_26', 'id_27',\n    'id_28', 'id_29', 'id_30', 'id_31', 'id_32', 'id_33', 'id_34', 'id_35',\n    'id_36', 'id_37', 'id_38', 'DeviceType', 'DeviceInfo', 'ProductCD', \n    'card4', 'card6', 'P_emaildomain', 'R_emaildomain', \n    'card1', 'card2', 'card3',  'card5', 'addr1', 'addr2', \n    'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9']\nfor col in cat_cols:\n    if col in train_df.columns:\n        le = preprocessing.LabelEncoder()\n        le.fit(list(train_df[col].astype(str).values) + list(test_df[col].astype(str).values))\n        train_df[col] = le.transform(list(train_df[col].astype(str).values))\n        test_df[col] = le.transform(list(test_df[col].astype(str).values))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2a632bed-879b-4509-b481-0142caabac24","_cell_guid":"0a9fd7e1-d770-4ba3-9ab5-e530077d1862","trusted":true},"cell_type":"code","source":"X = train_df.drop(['isFraud', 'TransactionID_x'], axis=1)\ny = train_df['isFraud']\n\ntest_df.drop(['TransactionID_x'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.impute import SimpleImputer\n\nmy_imputer = SimpleImputer()\nX = my_imputer.fit_transform(X)\ntest_df = my_imputer.transform(test_df)\n\ndel train_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tackling the data imbalance\nfrom imblearn.over_sampling import SMOTE\n\nsmote = SMOTE(ratio='minority')\nX, y = smote.fit_sample(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### LGBM"},{"metadata":{"_uuid":"7d1ba699-71c0-49f0-a2ff-cc41bd58399f","_cell_guid":"568dea88-85f2-493c-b931-d2eb574d4084","trusted":true},"cell_type":"code","source":"params = {'num_leaves': 491,\n          'min_child_weight': 0.03454472573214212,\n          'feature_fraction': 0.3797454081646243,\n          'bagging_fraction': 0.4181193142567742,\n          'min_data_in_leaf': 106,\n          'objective': 'binary',\n          'max_depth': -1,\n          'learning_rate': 0.006883242363721497,\n          \"boosting_type\": \"gbdt\",\n          \"bagging_seed\": 11,\n          \"metric\": 'auc',\n          \"verbosity\": -1,\n          'reg_alpha': 0.3899927210061127,\n          'reg_lambda': 0.6485237330340494,\n          'random_state': 47\n         }\n\nfolds = model_selection.TimeSeriesSplit(n_splits=5)\n\naucs = list()\ntraining_start_time = time.time()\nfor fold, (trn_idx, test_idx) in enumerate(folds.split(X, y)):\n    start_time = time.time()\n    print('Training on fold {}'.format(fold + 1))\n    \n    #trn_data = lgb.Dataset(X.iloc[trn_idx], label=y.iloc[trn_idx])\n    #val_data = lgb.Dataset(X.iloc[test_idx], label=y.iloc[test_idx])\n    trn_data = lgb.Dataset(X[trn_idx], label=y[trn_idx])\n    val_data = lgb.Dataset(X[test_idx], label=y[test_idx])\n    clf = lgb.train(params, trn_data, 10000, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds=500)\n    \n    aucs.append(clf.best_score['valid_1']['auc'])\n    \n    print('Fold {} finished in {}'.format(fold + 1, str(datetime.timedelta(seconds=time.time() - start_time))))\nprint('-' * 30)\nprint('Training has finished.')\nprint('Total training time is {}'.format(str(datetime.timedelta(seconds=time.time() - training_start_time))))\nprint('Mean AUC:', np.mean(aucs))\nprint('-' * 30)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c866f8c5-2d4e-4b4d-82b5-b948971662b6","_cell_guid":"69d33fcb-55b1-4cfb-ad94-05cd1c665aea","trusted":true},"cell_type":"code","source":"best_iter = clf.best_iteration","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e62f5ccd-980e-4e67-9214-ed9f016e9d30","_cell_guid":"e8a02f87-4f6f-49eb-a02a-325578967cea","trusted":true},"cell_type":"code","source":"clf = lgb.LGBMClassifier(**params, num_boost_round=best_iter)\nclf.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3a0f3bb2-09cf-4f2a-9321-01c4a07e12b5","_cell_guid":"fd22c7d4-463a-4e66-9d22-680b90b9a082","trusted":true},"cell_type":"code","source":"submit_df['isFraud'] = clf.predict_proba(test_df)[:, 1]\nsubmit_df.to_csv('ieee_cis_fraud_detection.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}